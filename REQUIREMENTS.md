# HAMMER (Hands-on Ansible Multi-node Machine Evaluation Runner)

## v1 refined requirements specification

Deterministic assignment authoring, generation, and auto-grading for Ansible labs using Vagrant + libvirt/KVM + AlmaLinux 9. Multi-node topology. Fully autogenerated tests. Local execution on the instructor machine.

This version incorporates explicit choices for determinism, variable resolution, inventories, scoring, networking, handler verification, and artifact structure.

---

## Scope and objectives

The system SHALL generate complete Ansible lab assignments from a single declarative specification (the spec). For each assignment, the system SHALL produce:

Student bundle

* Multi-node Vagrant environment using libvirt/KVM and AlmaLinux 9
* Student starter repository structure (playbooks, roles, defaults, inventory)
* Fully autogenerated pytest tests that students can run locally
* Documentation on how to run the lab and tests

Grading bundle

* A separate grading inventory root with group_vars and host_vars used for grading-time overlays
* A grading ansible.cfg selected via ANSIBLE_CONFIG
* Vault secrets and vault invocation configuration
* Fully autogenerated pytest tests

  * Core tests identical to student tests
  * Optional additional hidden tests, also autogenerated
* A grading runner that executes defined phases and exports artifacts

Lock artifact

* Spec hash
* Seed
* Resolved deterministic network plan (CIDR and node IPs)
* Resolved mutation values per phase
* Pinned versions (box, ansible-core, Python deps)
* Checksums of generated artifacts

Prohibitions

* No handwritten pytest test files are permitted in v1.
* All tests (including hidden tests) MUST be generated from the spec and generator code path.

Execution constraints

* Runs locally on instructor machine. No CI integration required in v1.
* The system SHALL NOT generate the correct Ansible solution automatically.

---

## Non-goals and explicit limits

* The grader will not enforce exact module selection, task ordering, or role structure beyond minimal entrypoints and file presence required for execution.
* The system will not attempt to prove variable origin. It enforces variable-driven solutions through:

  * controlled grading overlays
  * mutation phases
  * observed runtime variable snapshots
  * system-observable bindings

---

## Runtime environment requirements

Virtualization

* Provider: libvirt/KVM via Vagrant
* Vagrant environment MUST be multi-node
* Vagrant runs MUST be headless and non-interactive
* The grading runner MUST be able to run Vagrant lifecycle commands without manual input

Target OS

* AlmaLinux 9 only in v1
* Base box MUST be pinned to a specific version per assignment lock

Controller requirements (instructor machine)

* ansible-core pinned per lock
* Python dependencies pinned per lock:

  * pytest
  * testinfra
  * ansible-runner
  * helper libraries used by the grading runner
* A Python virtualenv per assignment is RECOMMENDED to avoid cross-assignment drift

---

## High-level architecture

Inputs

* Assignment spec file (YAML), the single source of truth

Generation pipeline

* Validate spec against a strict schema
* Resolve deterministic values using seed

  * network plan (CIDR, node IPs)
  * any other derived deterministic defaults
* Emit student bundle and grading bundle
* Emit generated pytest tests
* Emit a grading runner (Python CLI)
* Emit lock artifact capturing all resolved values and pins

Execution pipeline (grading)

* Bring up Vagrant VMs
* Run Ansible in multiple phases with controlled variable overlays
* After each converge phase, export observed runtime variable snapshots
* Collect ansible-runner artifacts (events, stats)
* Run generated pytest tests per node (sequential per node)
* Produce weighted score and artifacts

---

## Determinism and lock rules

Determinism rules

* Any derived choice MUST be derived from seed and recorded in lock
* Mutation values are explicitly specified in the spec in v1 (no generator randomness required)
* All external dependencies MUST be pinned in lock:

  * Vagrant box version
  * ansible-core
  * Python package versions

Lock artifact MUST include

* spec_hash: hash of canonicalized spec input
* seed
* resolved_network:

  * cidr
  * node_ip_map (node name to IP)
* resolved_phase_overlays: concrete values per phase
* pinned_versions:

  * almalinux_box
  * ansible_core
  * python_deps (name, version)
* checksums:

  * sha256 of every generated output file

---

## Assignment specification (DSL)

The spec is the single source of truth. It MUST be expressive enough that tests can be generated mechanically.

### Metadata

Required

* assignment_id: string
* assignment_version: string (assignment content version)
* spec_version: string (DSL version, fixed to "1.0" for v1)
* seed: int
* provider: "libvirt"
* os: "almalinux9"

Optional

* features:

  * vault: bool
  * selinux: bool
  * handlers: bool
  * reachability: bool

### Topology

Defines nodes and their group membership.

Required

* nodes: list of

  * name: string (stable identifier, used as hostname and inventory host)
  * groups: list of strings
  * resources:

    * cpu: int
    * ram_mb: int

Networking (v1 deterministic)

* The spec MAY omit explicit IPs.
* Generator MUST create:

  * one deterministic private CIDR for the assignment
  * static IP for each node in deterministic order
* The resulting CIDR and IPs MUST be recorded in lock and emitted into inventories.

Optional

* forwarded_ports: list of

  * host_port
  * guest_port
  * protocol
* dependencies: list of reachability or ordering edges

  * from_host
  * to_host
  * kind: "reachability" | "ordering"

### Entry points and student deliverables

Required

* playbook_path: string (default "site.yml")

Optional scaffolding expectations (scaffolding only)

* required_roles: list of role names
* required_files: list of paths that must exist (minimal entrypoints only)

Inventory expectation

* Student bundle MUST include a working inventory usable with playbook_path.
* Grading runner MUST NOT use student inventory.

### Variable contracts

Purpose

* Enable fully autogenerated tests without hardcoded values.
* Enforce variable-driven behavior through bindings and mutation.

Model

* Variable contracts declare what variables exist, their type, their student default, and their binding targets.
* Phase overlays select the active value for each variable per phase.

Each variable contract includes

* name: string
* type: "int" | "string" | "bool" | "list" | "dict"
* defaults:

  * student: value
* binding_targets: list of binding definitions
* allowed_values: explicit list of values (at least 2 when variable has bindings)
* grading_overlay_targets: list of overlay targets that may set this variable

  * overlay_kind: "group_vars" | "host_vars" | "inventory_vars"
  * target_name: group name or host name or "all"
* bindings_mode: "all" | "any" (default "all")
* binding_weights: optional per binding target weight (default 1.0)

Binding definition types (v1)

* service_listen_port:

  * service: string
  * protocol: "tcp" | "udp"
  * address: string
* firewall_port_open:

  * zone: string
  * protocol: "tcp" | "udp"
* template_contains:

  * path: string
  * pattern: string containing "{{ value }}" placeholder
* file_contains:

  * path: string
  * pattern: string containing "{{ value }}" placeholder
* file_exists:

  * path: string
* file_mode:

  * path: string
  * mode: string (octal-like, eg "0644")
* file_owner:

  * path: string
  * owner: string
  * group: string

Rules

* Any variable that is a learning objective MUST have at least one binding target.
* Any binding target MUST be testable on target OS without relying on unstable parsing.
* Variables with binding_targets MUST have at least two allowed_values to support mutation.

### Precedence scenarios

Purpose

* Enforce Ansible precedence outcomes by controlling overlays and verifying observed effects.

Each scenario includes

* name: string
* variable: variable name reference
* layers: ordered list of precedence sources used in this scenario, subset of:

  * role_default
  * role_vars
  * play_vars
  * vars_files
  * inventory_vars
  * group_vars
  * host_vars
  * extra_vars
* expected_winner: one of the listed layers
* bindings_to_verify: reference to variable binding_targets
* phase: "baseline" | "mutation" (default baseline)

Rules

* v1 MUST support generating at least:

  * group_vars overrides role defaults
  * host_vars overrides group_vars
  * extra_vars overrides all
  * inventory_vars vs group_vars (at least one scenario)

Notes

* The grader enforces precedence by controlling overlays and verifying observed bindings and snapshots.
* The grader does not inspect student repository structure to infer precedence sources.

### Behavioral contracts

Purpose

* Define required behaviors not strictly tied to a single variable.

Supported families (v1)

* packages

  * name
  * state: "present" | "absent"
  * node_selector: group or host
* services

  * name
  * enabled: bool
  * running: bool
  * node_selector
* firewall

  * open_ports: list of

    * port: int or variable ref
    * protocol
    * zone
  * node_selector
* selinux (only if features.selinux true)

  * file_contexts: list
  * booleans: list
  * node_selector
* users_groups

  * users: list (name, groups, home, shell, present)
  * groups: list (name, present)
  * node_selector
* files

  * list of (path, present, mode, owner, group, content_regex)
  * node_selector
* network_reachability (only if features.reachability true)

  * from_host
  * to_host
  * protocol
  * port: int or variable ref
  * expectation: "reachable" | "not_reachable"

### Handler and conditional contracts

Purpose

* Grade handlers and conditionals robustly using two verification channels.

Each handler contract includes

* handler_name: string (must match Ansible handler name)
* node_selector: group or host
* handler_target:

  * service: string
  * action: "restart" | "reload"
* trigger_conditions: list of triggers

  * file_changed: path
  * template_changed: path
  * variable_changed: variable name
* non_trigger_conditions: list

  * noop_rerun: true
  * unrelated_file_changed: path
* expected_runs:

  * baseline: "zero" | "at_least_once" | "exactly_once"
  * mutation: "zero" | "at_least_once" | "exactly_once"
  * idempotence: "zero" | "at_least_once" | "exactly_once"
* verification_modes: required set in v1

  * system_observable: true
  * runner_event: true

Rules

* Handler behavior MUST be checked in:

  * baseline converge (initial)
  * mutation converge (after variable changes)
  * idempotence converge (no changes expected)
* The grader MUST verify handler behavior using both:

  * system-observable evidence
  * ansible-runner event evidence

Handler matching semantics (v1)

* Handlers are identified by handler_name string only, case-sensitive.
* Role name and task UUID MUST NOT be required.
* Only handler execution events with status "ok" or "changed" count as executions.

### Idempotence policy

Config

* idempotence:

  * required: bool (default true)
  * allowed_changes: optional allowlist of task names or patterns (default empty)
  * enforcement:

    * require_changed_zero: bool (default true)
    * require_no_handlers: bool (default true)

Validation channels

* ansible-runner stats and per-task changed flags (primary)
* at least one system-level invariant test for critical files (secondary)

Conflict policy

* Ansible changed flags are authoritative for idempotence scoring.
* System invariants are sanity checks. If invariants fail while changed is zero, the result is an idempotence mismatch failure category.

### Vault contracts

If features.vault true, spec must define

* vault:

  * vault_ids: optional list
  * vaulted_vars_files: list of paths to create in student bundle as encrypted placeholders
  * vaulted_variables: list of variable names sourced from vault
  * bindings_to_verify: binding targets for vaulted values

Grading bundle must include

* vault password file(s) or vault-id mapping file(s)
* runner must execute non-interactively with vault access configured

Student bundle constraints

* Student tests MUST NOT require vault secrets to run.
* Vault bindings may only be fully verified in grading phases.

---

## Phase model and runner behavior

### Phase model

Minimum phases required in v1

Baseline converge

* Apply baseline overlays from grading inventory root
* Run playbook on all nodes via ansible-runner

Baseline snapshot export

* Run generated snapshot playbook to export observed runtime variable values per host

Baseline verify

* Run pytest tests per node, sequentially per node
* Export junit xml

Mutation converge

* Apply mutation overlays (variable values changed)
* Run playbook on all nodes

Mutation snapshot export

* Export observed snapshots for mutation phase

Mutation verify

* Run pytest tests per node, sequentially
* Verify handler expectations for this phase using runner events and system-observable checks

Idempotence converge

* Re-run playbook with same inputs as mutation converge

Idempotence snapshot export

* Export observed snapshots for idempotence phase

Idempotence verify

* Enforce idempotence policy:

  * changed == 0 unless allowed
  * no handlers executed unless allowed
* Run pytest tests per node, sequentially

Runner failure policy

* The runner SHOULD continue to subsequent phases even if a converge phase fails, to maximize artifact collection.
* Verification phases that depend on successful converge MUST record as skipped with explicit reason.

### Per-node execution policy

* Tests MUST run per node, sequentially, to simplify attribution and avoid timing issues.
* Multi-node reachability tests MUST run on a defined node and assert connectivity to others.

### Data capture requirements

Runner MUST capture

* vagrant logs
* ssh config extraction results
* ansible-runner artifacts directory for each converge phase

  * events
  * status
  * stats
* playbook stdout/stderr
* snapshots per phase per host
* pytest output and junit xml
* summarized scoring JSON
* environment pins used during grading (versions, lock references)

---

## Runtime variable snapshots

Purpose

* Provide deterministic, observed runtime values for tests without hardcoding.
* Support precedence and mutation verification without relying on inventory parsing.

Requirements

* Snapshot generation MUST be runner-controlled, not dependent on student repository content.
* After each converge phase, runner MUST execute a generated snapshot playbook using the same inventory and overlays as the converge phase.
* Snapshot playbook MUST be read-only on managed nodes.

Snapshot content

* Only variables explicitly declared in variable_contracts MUST be included.
* Missing variables MUST be recorded as null (not omitted) to make failures explicit.

Snapshot storage

* JSON per host per phase at:

  * artifacts/snapshots/<phase>/<host>.json

Tests and snapshots

* Tests MUST derive expected values from snapshot JSON for variable-driven checks.
* System state is still authoritative for verifying bindings. Snapshot is the expected-value input, not the proof.

Anti-gaming assumption

* Even if students attempt to manipulate variables at snapshot time, system-observable binding tests still must pass across phases, especially mutation.

---

## Inventory model

Student bundle inventory

* Provided for local execution and local tests.
* May be YAML or INI.
* Not used by grader.

Grading inventory root

* Source of truth for grading.
* Runner MUST use only grading inventory root.
* Grading overlays MUST be implemented as:

  * group_vars and host_vars directories
  * optional inventory vars
  * optional extra_vars for precedence scenarios

Inventory determinism

* Inventory MUST use static IPs from lock artifact.
* Hostnames MUST match node names.

---

## Autogenerated tests

The generator MUST emit pytest tests that use two complementary verification channels.

### Testinfra-based system verification

For each contract and binding:

* service enabled/running
* socket listening on port derived from snapshot variable values
* firewall rules effective

  * prefer verifying reachability plus stable firewall tooling checks
* SELinux context correct when selinux contracts exist
* template/file content contains expected rendered values
* file permissions and ownership

Variable-driven expected values

* Any expected value that is variable-driven MUST be derived from phase snapshots, not constants.

### Ansible-runner event-based verification

Generate checks that inspect runner event streams to validate:

* which tasks changed
* which handlers were notified
* which handlers executed
* idempotence (changed count, handler execution)
* conditional execution paths when required by spec

Event normalization rules (v1)

* Event parser MUST normalize across ansible-core minor versions where possible.
* Handler execution count uses handler_name matching rules.
* Events with transient or host-connection failures MUST be classified separately from contract failures.

### Anti-hardcoding enforcement

For every variable contract with bindings:

* Spec MUST define at least one mutation phase where the variable value changes.
* Tests MUST re-verify all bindings after mutation.

This makes hardcoding a single value insufficient.

---

## Generated artifacts

### Student bundle

Must include

* Vagrantfile (libvirt multi-node, static IP plan emitted)
* student inventory
* group_vars and host_vars with student defaults
* scaffolding repository structure (minimal)
* autogenerated pytest test suite

  * tests runnable locally without vault secrets
  * tests read student-phase snapshots produced by a local helper command OR fall back to student defaults only for local mode
* README with:

  * vagrant up
  * ansible-playbook invocation
  * pytest invocation
  * optional local snapshot export command (if provided)

Student local snapshot option (recommended)

* Provide a helper script that runs the same snapshot playbook in local mode, producing snapshots for local testing.
* This is not required for grading, but reduces student confusion.

### Grading bundle

Must include

* grading inventory root directory:

  * inventory
  * group_vars and host_vars overlays per phase
* grading ansible.cfg used via ANSIBLE_CONFIG
* vault password provisioning (if vault enabled)
* autogenerated pytest tests:

  * core tests identical to student tests
  * additional hidden tests may exist, also autogenerated
* grading runner entrypoint:

  * Python CLI
  * takes student repo path
  * produces score and artifacts

### Lock artifact

Must include all items listed under determinism and lock rules.

---

## Scoring model

Scoring goals

* Weighted scoring with partial credit.
* Phase-aware aggregation.
* No global hard fail gates in v1, but severe failures should strongly reduce score.

Contract scoring

* Each contract has weight (default 1.0).
* Variable contract with multiple binding targets scores proportionally:

  * binding_target_score is pass or fail
  * contract_raw = weighted_average(binding_target_score, binding_weight)
  * contract_points = contract_weight * contract_raw

Phase scoring

* Baseline verification contributes 40 percent of total
* Mutation verification contributes 40 percent of total
* Idempotence verification contributes 20 percent of total

Idempotence scoring

* Idempotence contributes via dedicated checks:

  * changed == 0 requirement (weighted)
  * no handlers executed requirement (weighted)
  * plus any normal system tests re-run in idempotence verify

Failure classification

* Converge failure: phase verification skipped, points for that phase become 0, artifacts still exported
* Verification failure: contract failures reduce points proportionally
* Infrastructure failure (Vagrant, SSH): scored as 0 for affected phases, classified distinctly in score report

Score report output

* score.json includes:

  * total_score, max_score
  * per-phase earned and max
  * per-contract breakdown including reasons
  * list of skipped tests and why
  * references to artifact paths

---

## Implementation minimalism (v1)

To keep v1 achievable:

* Provide a small Python CLI with two subcommands:

  * build: generate bundles and lock
  * grade: run phases on a student repo path and output artifacts

CLI contract (normative)

* hammer build --spec SPEC.yml --out OUTDIR
* hammer grade --student-path PATH --grading-bundle BUNDLE --lock LOCK.json --out OUTDIR

Strict schema validation

* Generator MUST validate the spec against a strict schema and fail fast.
* Unknown keys SHOULD be rejected to avoid silent misconfiguration.

---

## Known hard edges and guardrails

Event stream brittleness

* v1 should pin ansible-core and ansible-runner tightly.
* Event parsing MUST be normalized and covered by unit tests using recorded fixture event streams.

Firewall verification instability

* Prefer end-to-end reachability plus a stable local command check.
* Avoid parsing verbose firewall output that varies by version.

Snapshot extraction pitfalls

* Missing vars must be explicit null.
* Snapshot playbook must not assume vars exist on all hosts.

---
